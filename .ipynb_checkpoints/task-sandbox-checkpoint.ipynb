{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests as re\n",
    "import pandas as pd\n",
    "import pandas.io.sql as sqlio\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "# https://cloud.google.com/sql/docs/postgres/connect-external-app#languages\n",
    "import psycopg2\n",
    "conn = psycopg2.connect(user='airflow', password='Xypherium-0',\n",
    "                        dbname='jpstat',\n",
    "                        host='35.224.240.50')\n",
    "\n",
    "from google.cloud import storage\n",
    "bucket_name = \"i-agility-212104.appspot.com\"\n",
    "mdir = os.path.join('extracts', 'monthly_reports')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def files_review_task():\n",
    "    \n",
    "\n",
    "#Retrieve all months currently available \n",
    "main_table = []\n",
    "#url = input(\"http://www.e-stat.go.jp/SG1/estat/OtherListE.do?bid=000001006005&cycode=1\")\n",
    "url = \"http://www.e-stat.go.jp/SG1/estat/OtherListE.do?bid=000001006005&cycode=1\"\n",
    "path='https://www.e-stat.go.jp'\n",
    "r = re.get(url)\n",
    "data = r.text\n",
    "year='None'\n",
    "soup = BeautifulSoup(data, \"lxml\")\n",
    "table = soup.find('div', {'class': 'stat-cycle_sheet'})\n",
    "for year_section in table.find_all('ul', {'class': 'stat-cycle_ul_other'}):\n",
    "    header = year_section.find('li', {'class': 'stat-cycle_header'})\n",
    "    year = header.find('span').get_text(' ', strip=True)\n",
    "    #   print('year changed to ' + year)\n",
    "    months_section = year_section.find('li', {'class': 'stat-cycle_item'})\n",
    "    for month_row in months_section.find_all('div'):\n",
    "        month_a = month_row.find('a')\n",
    "        month = month_a.get_text().rstrip('.\\n')\n",
    "        monthurl = path + month_a.get('href')\n",
    "\n",
    "        main_table.append({\n",
    "            'year': year,\n",
    "            'month': month,\n",
    "            'url': monthurl\n",
    "        })\n",
    "\n",
    "top_df = pd.DataFrame(main_table)\n",
    "\n",
    "logging.info('DataFrame of months generated: ' + str(top_df.size) + ' months available, from ' \n",
    "    + top_df.loc[len(top_df)-1,'year'] + ' ' + top_df.loc[len(top_df)-1,'month'] + ' to ' \n",
    "    + top_df.loc[0,'year'] + ' ' + top_df.loc[0,'month'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "retrieve_month_excels_starttime = datetime.utcnow()\n",
    "logging.info('Starting to retrieve urls of every excel sheet at ' + str(retrieve_month_excels_starttime) + ' UTC.')\n",
    "\n",
    "excels_df = pd.concat([retrieve_month_excels(murl, path) for murl in top_df['url']])\n",
    "excelref_df = top_df.merge(excels_df, how='left', on='url')\n",
    "\n",
    "logging.info('Excel URLs retrieved in ' + str(datetime.utcnow() - retrieve_month_excels_starttime) + '.')\n",
    "logging.info(str(len(excelref_df)) + ' files to retrieve. Writing table to database...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tempdf = excelref_df.copy()\n",
    "tempdf['updated_on'] = retrieve_month_excels_starttime.strftime('%Y-%m-%d')\n",
    "tempdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"SELECT year, month, url, excel_num, excel_description, excel_url FROM public.jpstat_excel_urls;\"\n",
    "curr_table_df = sqlio.read_sql_query(sql, conn)\n",
    "curr_table_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "disjoint_df = pd.concat([curr_table_df, excelref_df]).drop_duplicates(keep=False, subset=['excel_url'])\n",
    "new_files_df = pd.merge(disjoint_df, excelref_df, how='inner')\n",
    "new_files_df = new_files_df[curr_table_df.columns]\n",
    "new_files_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert DataFrame to stream and upload to PostgreSQL table on Google Cloud SQL\n",
    "cur = conn.cursor()\n",
    "excelurl_textstream = io.StringIO()\n",
    "upload_df = new_files_df.copy()\n",
    "upload_df['excel_description'].replace(['\\n', '\\t'], '', regex=True, inplace=True)\n",
    "\n",
    "upload_df.to_csv(excelurl_textstream, sep='\\t', header=False, index=False, quoting=csv.QUOTE_NONE)\n",
    "excelurl_textstream.seek(0) \n",
    "cur.copy_from(excelurl_textstream, 'jpstat_excel_urls', null=\"\") # null values become ''\n",
    "conn.commit()\n",
    "\n",
    "logging.info('Excel URL database table updated.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Returns a dataframe of details on excel sheets of data available for a given url\n",
    "for a particular month\n",
    "\"\"\"\n",
    "def retrieve_month_excels(murl, path):\n",
    "    mcols = ['url', 'excel_num', 'excel_description', 'excel_url']\n",
    "    mdf = pd.DataFrame(columns=mcols)\n",
    "    mr = re.get(murl)\n",
    "    mdata = mr.text\n",
    "    msoup = BeautifulSoup(mdata, \"lxml\")\n",
    "    mtable = msoup.find('div', {'class': 'stat-dataset_list-body'})\n",
    "    for row in mtable.find_all('article', {'class': 'stat-dataset_list-item'}):\n",
    "        excel_num = row.find('li', {'class': 'stat-dataset_list-detail-item stat-dataset_list-border-top'}).contents[0].replace('\\n','')\n",
    "        excel_description = row.find('a').contents[0]\n",
    "        excel_url = ''\n",
    "        excel_a = row.find_all('a')[1]\n",
    "        \n",
    "        if(excel_a['data-file_type'] == 'EXCEL'):\n",
    "            excel_url = path + excel_a['href']\n",
    "        mdfrow = pd.DataFrame([[murl, excel_num, excel_description, excel_url]], columns=mcols)\n",
    "        if(len(mdf)==0):\n",
    "            mdf = mdfrow\n",
    "        else:\n",
    "            mdf = mdf.append(mdfrow, ignore_index=True) #why the hell doesn't df.append work inplace?? Didn't it always use to?\n",
    "    logging.info(\"Retrieved excel URLs from month-URL: \" + murl + '.')\n",
    "    return(mdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Now working in C:\\Users\\friedemann.ang\\Documents\\repos\\jpstat\n",
      "INFO:root:Saving files to C:\\Users\\friedemann.ang\\Documents\\repos\\jpstat\\extracts\\monthly_reports\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "['extracts/monthly_reports/2018/01Jan/1.xls', 'extracts/monthly_reports/2018/01Jan/2.xls', 'extracts/monthly_reports/2018/01Jan/3-1.xls', 'extracts/monthly_reports/2018/01Jan/3-2.xls']\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "logging.info('Now working in ' + cwd)\n",
    "\n",
    "if not os.path.exists(mdir):\n",
    "    os.makedirs(mdir)\n",
    "logging.info('Saving files to ' + os.path.join(cwd, mdir))\n",
    "\n",
    "sql = \"SELECT year, month, url, excel_num, excel_description, excel_url FROM public.jpstat_excel_urls;\"\n",
    "curr_table_df = sqlio.read_sql_query(sql, conn)\n",
    "\n",
    "# Building a dictionary of month names in a format more suitable for dirnames\n",
    "months = curr_table_df.month.unique() #do not sort, retain the order\n",
    "monthnum = list(range(1,13,1))\n",
    "monthdirs = [str(num).zfill(2) + month for num,month in zip(monthnum, months)]\n",
    "monthnamedict = dict(zip(months, monthdirs))\n",
    "\n",
    "\"\"\"\n",
    "List files already on google cloud storage, and compare them with curr_table_df. \n",
    "If files don't already exist on google cloud storage, download them and upload them to gcs\n",
    "\"\"\"\n",
    "existing_files_list = list_xls_blobs(bucket_name)\n",
    "print(len(existing_files_list))\n",
    "print(str(existing_files_list[:4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_xls_blobs(bucket_name):\n",
    "    \"\"\"Lists all the blobs in the bucket.\"\"\"\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "\n",
    "    filelist = []\n",
    "    blobs = bucket.list_blobs()\n",
    "    \n",
    "    for blob in blobs:\n",
    "        path = str(blob.name)\n",
    "        if(path[-1:] != '/'):\n",
    "            filelist.append(blob.name)\n",
    "    \n",
    "    return filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>url</th>\n",
       "      <th>excel_num</th>\n",
       "      <th>excel_description</th>\n",
       "      <th>excel_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>Jan</td>\n",
       "      <td>https://www.e-stat.go.jp/en/stat-search/files?..</td>\n",
       "      <td>0</td>\n",
       "      <td>Number of Intra-prefectural Migrants, In-migr....</td>\n",
       "      <td>https://www.e-stat.go.jp/en/stat-search/file-d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>Jan</td>\n",
       "      <td>https://www.e-stat.go.jp/en/stat-search/files?...</td>\n",
       "      <td>1</td>\n",
       "      <td>Number of Intra-prefectural Migrants, In-migra...</td>\n",
       "      <td>https://www.e-stat.go.jp/en/stat-search/file-d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>Jan</td>\n",
       "      <td>https://www.e-stat.go.jp/en/stat-search/files?...</td>\n",
       "      <td>2</td>\n",
       "      <td>Number of Inter-prefectural Migrants by Sex an...</td>\n",
       "      <td>https://www.e-stat.go.jp/en/stat-search/file-d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>Jan</td>\n",
       "      <td>https://www.e-stat.go.jp/en/stat-search/files?...</td>\n",
       "      <td>3-1</td>\n",
       "      <td>Number of In-migrants from Other Prefectures b...</td>\n",
       "      <td>https://www.e-stat.go.jp/en/stat-search/file-d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018</td>\n",
       "      <td>Jan</td>\n",
       "      <td>https://www.e-stat.go.jp/en/stat-search/files?...</td>\n",
       "      <td>3-2</td>\n",
       "      <td>Number of Out-migrants to Other Prefectures by...</td>\n",
       "      <td>https://www.e-stat.go.jp/en/stat-search/file-d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year month                                                url excel_num  \\\n",
       "0  2018   Jan   https://www.e-stat.go.jp/en/stat-search/files?..         0   \n",
       "1  2018   Jan  https://www.e-stat.go.jp/en/stat-search/files?...         1   \n",
       "2  2018   Jan  https://www.e-stat.go.jp/en/stat-search/files?...         2   \n",
       "3  2018   Jan  https://www.e-stat.go.jp/en/stat-search/files?...       3-1   \n",
       "4  2018   Jan  https://www.e-stat.go.jp/en/stat-search/files?...       3-2   \n",
       "\n",
       "                                   excel_description  \\\n",
       "0  Number of Intra-prefectural Migrants, In-migr....   \n",
       "1  Number of Intra-prefectural Migrants, In-migra...   \n",
       "2  Number of Inter-prefectural Migrants by Sex an...   \n",
       "3  Number of In-migrants from Other Prefectures b...   \n",
       "4  Number of Out-migrants to Other Prefectures by...   \n",
       "\n",
       "                                           excel_url  \n",
       "0  https://www.e-stat.go.jp/en/stat-search/file-d...  \n",
       "1  https://www.e-stat.go.jp/en/stat-search/file-d...  \n",
       "2  https://www.e-stat.go.jp/en/stat-search/file-d...  \n",
       "3  https://www.e-stat.go.jp/en/stat-search/file-d...  \n",
       "4  https://www.e-stat.go.jp/en/stat-search/file-d...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_table_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_table_df['path'] = mdir + '/' + curr_table_df['year'] + '/' + curr_table_df['month'].map(monthnamedict) + '/' + curr_table_df['excel_num'] + '.xls'\n",
    "curr_table_df['path'] = [x.replace('\\\\', '/') for x in curr_table_df['path']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "617\n",
      "587\n"
     ]
    }
   ],
   "source": [
    "print(len(curr_table_df))\n",
    "download_table = curr_table_df.copy()\n",
    "download_table = download_table[~download_table['path'].isin(existing_files_list)]\n",
    "print(len(download_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
