{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a guide on how to utilize Google Cloud Storage as a Data Lake."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Go to https://console.cloud.google.com/apis/credentials/serviceaccountkey and create a new service account, set as the Project Owner. \n",
    "2. Save the JSON file that downloads automatically to a location of your choice.\n",
    "3. Add the JSON filepath to your GOOGLE_APPLICATION_CREDENTIALS environment variable.\n",
    "4. Refer to Jupyter Notebook cloudy-broth in jpstat for examples on API calls.\n",
    "5. To more easily manage files from the command line, use the gsutil tool: https://cloud.google.com/storage/docs/gsutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join('extracts', 'monthly_reports')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = \"i-agility-212104.appspot.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file200601_1dir = os.path.join(filepath, '2006')\n",
    "file200601_1name = os.path.join('01Jan', '2.xls')\n",
    "file200601_1path = os.path.join(file200601_1dir, file200601_1name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['extracts\\\\monthly_reports\\\\2018\\\\01Jan\\\\1.xls', 'extracts\\\\monthly_reports\\\\2018\\\\01Jan\\\\2.xls', 'extracts\\\\monthly_reports\\\\2018\\\\01Jan\\\\3-1.xls', 'extracts\\\\monthly_reports\\\\2018\\\\01Jan\\\\3-2.xls', 'extracts\\\\monthly_reports\\\\2018\\\\01Jan\\\\3-3.xls', 'extracts\\\\monthly_reports\\\\2018\\\\02Feb\\\\1.xls', 'extracts\\\\monthly_reports\\\\2018\\\\02Feb\\\\2.xls', 'extracts\\\\monthly_reports\\\\2018\\\\02Feb\\\\3-1.xls', 'extracts\\\\monthly_reports\\\\2018\\\\02Feb\\\\3-2.xls', 'extracts\\\\monthly_reports\\\\2018\\\\02Feb\\\\3-3.xls', 'extracts\\\\monthly_reports\\\\2018\\\\03Mar\\\\1.xls', 'extracts\\\\monthly_reports\\\\2018\\\\03Mar\\\\2.xls', 'extracts\\\\monthly_reports\\\\2018\\\\03Mar\\\\3-1.xls', 'extracts\\\\monthly_reports\\\\2018\\\\03Mar\\\\3-2.xls', 'extracts\\\\monthly_reports\\\\2018\\\\03Mar\\\\3-3.xls', 'extracts\\\\monthly_reports\\\\2018\\\\04Apr\\\\1.xls', 'extracts\\\\monthly_reports\\\\2018\\\\04Apr\\\\2.xls', 'extracts\\\\monthly_reports\\\\2018\\\\04Apr\\\\3-1.xls', 'extracts\\\\monthly_reports\\\\2018\\\\04Apr\\\\3-2.xls', 'extracts\\\\monthly_reports\\\\2018\\\\04Apr\\\\3-3.xls', 'extracts\\\\monthly_reports\\\\2018\\\\05May\\\\1.xls', 'extracts\\\\monthly_reports\\\\2018\\\\05May\\\\2.xls', 'extracts\\\\monthly_reports\\\\2018\\\\05May\\\\3-1.xls', 'extracts\\\\monthly_reports\\\\2018\\\\05May\\\\3-2.xls', 'extracts\\\\monthly_reports\\\\2018\\\\05May\\\\3-3.xls', 'extracts\\\\monthly_reports\\\\2018\\\\06Jun\\\\1.xls', 'extracts\\\\monthly_reports\\\\2018\\\\06Jun\\\\2.xls', 'extracts\\\\monthly_reports\\\\2018\\\\06Jun\\\\3-1.xls', 'extracts\\\\monthly_reports\\\\2018\\\\06Jun\\\\3-2.xls', 'extracts\\\\monthly_reports\\\\2018\\\\06Jun\\\\3-3.xls']\n"
     ]
    }
   ],
   "source": [
    "testdir = os.path.join('extracts', 'monthly_reports', '2018')\n",
    "filepathlist = []\n",
    "for dirpath, subdir, files in os.walk(testdir):\n",
    "\tfor filename in files:\n",
    "\t\tif filename.endswith('.xls'):\n",
    "\t\t\tfilepathlist.append(os.path.join(dirpath, filename))\n",
    "\n",
    "print(filepathlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File extracts\\monthly_reports\\2018\\01Jan\\1.xls uploaded to extracts/monthly_reports/2018/01Jan/1.xls.\n",
      "File extracts\\monthly_reports\\2018\\01Jan\\2.xls uploaded to extracts/monthly_reports/2018/01Jan/2.xls.\n",
      "File extracts\\monthly_reports\\2018\\01Jan\\3-1.xls uploaded to extracts/monthly_reports/2018/01Jan/3-1.xls.\n",
      "File extracts\\monthly_reports\\2018\\01Jan\\3-2.xls uploaded to extracts/monthly_reports/2018/01Jan/3-2.xls.\n",
      "File extracts\\monthly_reports\\2018\\01Jan\\3-3.xls uploaded to extracts/monthly_reports/2018/01Jan/3-3.xls.\n",
      "File extracts\\monthly_reports\\2018\\02Feb\\1.xls uploaded to extracts/monthly_reports/2018/02Feb/1.xls.\n",
      "File extracts\\monthly_reports\\2018\\02Feb\\2.xls uploaded to extracts/monthly_reports/2018/02Feb/2.xls.\n",
      "File extracts\\monthly_reports\\2018\\02Feb\\3-1.xls uploaded to extracts/monthly_reports/2018/02Feb/3-1.xls.\n",
      "File extracts\\monthly_reports\\2018\\02Feb\\3-2.xls uploaded to extracts/monthly_reports/2018/02Feb/3-2.xls.\n",
      "File extracts\\monthly_reports\\2018\\02Feb\\3-3.xls uploaded to extracts/monthly_reports/2018/02Feb/3-3.xls.\n",
      "File extracts\\monthly_reports\\2018\\03Mar\\1.xls uploaded to extracts/monthly_reports/2018/03Mar/1.xls.\n",
      "File extracts\\monthly_reports\\2018\\03Mar\\2.xls uploaded to extracts/monthly_reports/2018/03Mar/2.xls.\n",
      "File extracts\\monthly_reports\\2018\\03Mar\\3-1.xls uploaded to extracts/monthly_reports/2018/03Mar/3-1.xls.\n",
      "File extracts\\monthly_reports\\2018\\03Mar\\3-2.xls uploaded to extracts/monthly_reports/2018/03Mar/3-2.xls.\n",
      "File extracts\\monthly_reports\\2018\\03Mar\\3-3.xls uploaded to extracts/monthly_reports/2018/03Mar/3-3.xls.\n",
      "File extracts\\monthly_reports\\2018\\04Apr\\1.xls uploaded to extracts/monthly_reports/2018/04Apr/1.xls.\n",
      "File extracts\\monthly_reports\\2018\\04Apr\\2.xls uploaded to extracts/monthly_reports/2018/04Apr/2.xls.\n",
      "File extracts\\monthly_reports\\2018\\04Apr\\3-1.xls uploaded to extracts/monthly_reports/2018/04Apr/3-1.xls.\n",
      "File extracts\\monthly_reports\\2018\\04Apr\\3-2.xls uploaded to extracts/monthly_reports/2018/04Apr/3-2.xls.\n",
      "File extracts\\monthly_reports\\2018\\04Apr\\3-3.xls uploaded to extracts/monthly_reports/2018/04Apr/3-3.xls.\n",
      "File extracts\\monthly_reports\\2018\\05May\\1.xls uploaded to extracts/monthly_reports/2018/05May/1.xls.\n",
      "File extracts\\monthly_reports\\2018\\05May\\2.xls uploaded to extracts/monthly_reports/2018/05May/2.xls.\n",
      "File extracts\\monthly_reports\\2018\\05May\\3-1.xls uploaded to extracts/monthly_reports/2018/05May/3-1.xls.\n",
      "File extracts\\monthly_reports\\2018\\05May\\3-2.xls uploaded to extracts/monthly_reports/2018/05May/3-2.xls.\n",
      "File extracts\\monthly_reports\\2018\\05May\\3-3.xls uploaded to extracts/monthly_reports/2018/05May/3-3.xls.\n",
      "File extracts\\monthly_reports\\2018\\06Jun\\1.xls uploaded to extracts/monthly_reports/2018/06Jun/1.xls.\n",
      "File extracts\\monthly_reports\\2018\\06Jun\\2.xls uploaded to extracts/monthly_reports/2018/06Jun/2.xls.\n",
      "File extracts\\monthly_reports\\2018\\06Jun\\3-1.xls uploaded to extracts/monthly_reports/2018/06Jun/3-1.xls.\n",
      "File extracts\\monthly_reports\\2018\\06Jun\\3-2.xls uploaded to extracts/monthly_reports/2018/06Jun/3-2.xls.\n",
      "File extracts\\monthly_reports\\2018\\06Jun\\3-3.xls uploaded to extracts/monthly_reports/2018/06Jun/3-3.xls.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Change path delimiters to unix format if necessary\n",
    "[upload_blob(bucket_name, source_file, source_file.replace('\\\\', '/')) for source_file in filepathlist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cells below this point are functions lifted directly from https://cloud.google.com/storage/docs/uploading-objects and associated pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Deleting buckets is supported by the Python API, but buckets must be empty. \n",
    "To be safer, perform bucket operations using gsutil or from the Google Cloud Platform UI.\n",
    "\"\"\"\n",
    "def create_bucket(bucket_name):\n",
    "    \"\"\"Creates a new bucket.\"\"\"\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.create_bucket(bucket_name)\n",
    "    print('Bucket {} created'.format(bucket.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "https://cloud.google.com/storage/docs/uploading-objects#storage-upload-object-python\n",
    "\"\"\"\n",
    "def upload_blob(bucket_name, source_file_name, destination_blob_name):\n",
    "    \"\"\"Uploads a file to the bucket.\"\"\"\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "    blob.upload_from_filename(source_file_name)\n",
    "\n",
    "    print('File {} uploaded to {}.'.format(\n",
    "        source_file_name,\n",
    "        destination_blob_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "https://cloud.google.com/storage/docs/listing-objects\n",
    "\"\"\"\n",
    "def list_blobs(bucket_name):\n",
    "    \"\"\"Lists all the blobs in the bucket.\"\"\"\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "\n",
    "    blobs = bucket.list_blobs()\n",
    "\n",
    "    for blob in blobs:\n",
    "        print(blob.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_blobs_with_prefix(bucket_name, prefix, delimiter=None):\n",
    "    \"\"\"Lists all the blobs in the bucket that begin with the prefix.\n",
    "\n",
    "    This can be used to list all blobs in a \"folder\", e.g. \"public/\".\n",
    "\n",
    "    The delimiter argument can be used to restrict the results to only the\n",
    "    \"files\" in the given \"folder\". Without the delimiter, the entire tree under\n",
    "    the prefix is returned. For example, given these blobs:\n",
    "\n",
    "        /a/1.txt\n",
    "        /a/b/2.txt\n",
    "\n",
    "    If you just specify prefix = '/a', you'll get back:\n",
    "\n",
    "        /a/1.txt\n",
    "        /a/b/2.txt\n",
    "\n",
    "    However, if you specify prefix='/a' and delimiter='/', you'll get back:\n",
    "\n",
    "        /a/1.txt\n",
    "\n",
    "    \"\"\"\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "\n",
    "    blobs = bucket.list_blobs(prefix=prefix, delimiter=delimiter)\n",
    "\n",
    "    print('Blobs:')\n",
    "    for blob in blobs:\n",
    "        print(blob.name)\n",
    "\n",
    "    if delimiter:\n",
    "        print('Prefixes:')\n",
    "        for prefix in blobs.prefixes:\n",
    "            print(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "https://cloud.google.com/storage/docs/downloading-objects\n",
    "\"\"\"\n",
    "def download_blob(bucket_name, source_blob_name, destination_file_name):\n",
    "    \"\"\"Downloads a blob from the bucket.\"\"\"\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(source_blob_name)\n",
    "\n",
    "    blob.download_to_filename(destination_file_name)\n",
    "\n",
    "    print('Blob {} downloaded to {}.'.format(\n",
    "        source_blob_name,\n",
    "        destination_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "https://cloud.google.com/storage/docs/renaming-copying-moving-objects\n",
    "\n",
    "Deleting blobs is not supported in the Python API. To move, i.e. copy then delete, use 'gsutil mv'.\n",
    "\"\"\"\n",
    "def rename_blob(bucket_name, blob_name, new_name):\n",
    "    \"\"\"Renames a blob.\"\"\"\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(blob_name)\n",
    "\n",
    "    new_blob = bucket.rename_blob(blob, new_name)\n",
    "\n",
    "    print('Blob {} has been renamed to {}'.format(\n",
    "        blob.name, new_blob.name))\n",
    "\n",
    "\n",
    "def copy_blob(bucket_name, blob_name, new_bucket_name, new_blob_name):\n",
    "    \"\"\"Copies a blob from one bucket to another with a new name.\"\"\"\n",
    "    storage_client = storage.Client()\n",
    "    source_bucket = storage_client.get_bucket(bucket_name)\n",
    "    source_blob = source_bucket.blob(blob_name)\n",
    "    destination_bucket = storage_client.get_bucket(new_bucket_name)\n",
    "\n",
    "    new_blob = source_bucket.copy_blob(\n",
    "        source_blob, destination_bucket, new_blob_name)\n",
    "\n",
    "    print('Blob {} in bucket {} copied to blob {} in bucket {}.'.format(\n",
    "        source_blob.name, source_bucket.name, new_blob.name,\n",
    "        destination_bucket.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Setting or adding metadata is not properly supported through the python API\n",
    "So, use gsutil: 'gsutil setmeta -h \"[METADATA_KEY]:[METADATA_VALUE]\" gs://[BUCKET_NAME]/[OBJECT_NAME]'\n",
    "or, use the Google Cloud Platform UI.\n",
    "\"\"\"\n",
    "def blob_metadata(bucket_name, blob_name):\n",
    "    \"\"\"Prints out a blob's metadata.\"\"\"\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    blob = bucket.get_blob(blob_name)\n",
    "\n",
    "    print('Blob: {}'.format(blob.name))\n",
    "    print('Bucket: {}'.format(blob.bucket.name))\n",
    "    print('Storage class: {}'.format(blob.storage_class))\n",
    "    print('ID: {}'.format(blob.id))\n",
    "    print('Size: {} bytes'.format(blob.size))\n",
    "    print('Updated: {}'.format(blob.updated))\n",
    "    print('Generation: {}'.format(blob.generation))\n",
    "    print('Metageneration: {}'.format(blob.metageneration))\n",
    "    print('Etag: {}'.format(blob.etag))\n",
    "    print('Owner: {}'.format(blob.owner))\n",
    "    print('Component count: {}'.format(blob.component_count))\n",
    "    print('Crc32c: {}'.format(blob.crc32c))\n",
    "    print('md5_hash: {}'.format(blob.md5_hash))\n",
    "    print('Cache-control: {}'.format(blob.cache_control))\n",
    "    print('Content-type: {}'.format(blob.content_type))\n",
    "    print('Content-disposition: {}'.format(blob.content_disposition))\n",
    "    print('Content-encoding: {}'.format(blob.content_encoding))\n",
    "    print('Content-language: {}'.format(blob.content_language))\n",
    "    print('Metadata: {}'.format(blob.metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To handle streaming uploads and downloads, use the boto client library plugin: https://cloud.google.com/storage/docs/boto-plugin\n",
    "\"\"\"\n",
    "\n",
    "#Uploads:\n",
    "\"\"\"\n",
    "dst_uri = boto.storage_uri(<bucket> + '/' + <object>, 'gs')\n",
    "dst_uri.new_key().set_contents_from_stream(<stream object>)\n",
    "\n",
    "E.g.\n",
    "filename = 'data_file'\n",
    "MY_BUCKET = 'my_app_bucket'\n",
    "my_stream = open(filename, 'rb')\n",
    "dst_uri = boto.storage_uri(MY_BUCKET + '/' + filename, 'gs')\n",
    "dst_uri.new_key().set_contents_from_stream(my_stream)\n",
    "\"\"\"\n",
    "\n",
    "#Downloads:\n",
    "\"\"\"\n",
    "import sys\n",
    "\n",
    "src_uri = boto.storage_uri(<bucket> + '/' + <object>, 'gs')\n",
    "src_uri.get_key().get_file(sys.stdout)\n",
    "\n",
    "E.g.\n",
    "downloaded_file = 'saved_data_file'\n",
    "MY_BUCKET = 'my_app_bucket'\n",
    "object_name = 'data_file'\n",
    "src_uri = boto.storage_uri(MY_BUCKET + '/' + object_name, 'gs')\n",
    "src_uri.get_key().get_file(sys.stdout)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_blob(bucket_name, blob_name):\n",
    "    \"\"\"Deletes a blob from the bucket.\"\"\"\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(blob_name)\n",
    "\n",
    "    blob.delete()\n",
    "\n",
    "    print('Blob {} deleted.'.format(blob_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Bucket Labels are key:value pairs. You can add multiple labels to a single bucket.\n",
    "\"\"\"\n",
    "def add_bucket_label(bucket_name):\n",
    "    \"\"\"Add a label to a bucket.\"\"\"\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "\n",
    "    labels = bucket.labels\n",
    "    labels['example'] = 'label'\n",
    "    bucket.labels = labels\n",
    "    bucket.patch()\n",
    "\n",
    "    print('Updated labels on {}.'.format(bucket.name))\n",
    "    pprint.pprint(bucket.labels)\n",
    "    \n",
    "def get_bucket_labels(bucket_name):\n",
    "    \"\"\"Prints out a bucket's labels.\"\"\"\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    labels = bucket.labels\n",
    "    pprint.pprint(labels)\n",
    "    \n",
    "def remove_bucket_label(bucket_name):\n",
    "    \"\"\"Remove a label from a bucket.\"\"\"\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "\n",
    "    labels = bucket.labels\n",
    "\n",
    "    if 'example' in labels:\n",
    "        del labels['example']\n",
    "\n",
    "    bucket.labels = labels\n",
    "    bucket.patch()\n",
    "\n",
    "    print('Updated labels on {}.'.format(bucket.name))\n",
    "    pprint.pprint(bucket.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Object versioning helps maintain live and archived versions of blobs. However, to accommodate inexperienced users, I recommend\n",
    "managing files using appropriate filenames, metadata, and bucket labels, when using GCS as a data lake. \n",
    "\n",
    "Object versioning may be more appropriate for use in maintaining live app resources.\n",
    "\n",
    "To learn how to enable, read:\n",
    "\n",
    "https://cloud.google.com/storage/docs/using-object-versioning\n",
    "\n",
    "For an example of how versioning works, read:\n",
    "\n",
    "https://cloud.google.com/storage/docs/object-versioning#example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"You can make individual blobs(files) public. \n",
    "I recommend you handle this in gsutil, because you seldom will need to do this programatically.\n",
    "\n",
    "To apply to a file:\n",
    "gsutil acl ch -u AllUsers:R gs://[BUCKET_NAME]/[OBJECT_NAME]\n",
    "\n",
    "To apply to a bucket:\n",
    "gsutil iam ch allUsers:objectViewer gs://[BUCKET_NAME]\"\"\"\n",
    "        \n",
    "def make_blob_public(bucket_name, blob_name):\n",
    "    \"\"\"Makes a blob publicly accessible.\"\"\"\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(blob_name)\n",
    "\n",
    "    blob.make_public()\n",
    "\n",
    "    print('Blob {} is publicly accessible at {}'.format(\n",
    "        blob.name, blob.public_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I recommend all other access control operations be performed using gsutil or the Google Cloud Platform UI.\n",
    "https://cloud.google.com/storage/docs/access-control/using-iam-permissions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
